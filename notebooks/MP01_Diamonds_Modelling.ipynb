{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqOL5KVx-GOd"
   },
   "source": [
    "## Problem Statement\n",
    "\n",
    "Our customer, Don Francesco, manages a large jewelry store and seeks to use a comprehensive dataset he has gathered to automatically determine the prices for diamonds customers want to sell to him.\n",
    "\n",
    "This dataset includes details on the characteristics and prices of diamonds, which closely reflect actual market values.\n",
    "\n",
    "Our goal is to develop a model that can accurately predict the market price of a diamond based on its characteristics.\n",
    "\n",
    "### Dataset\n",
    "The dataset provides information on diamond prices and their attributes that impact their value, expressed in 2008 US Dollars.\n",
    "\n",
    "Key attributes include the 4 Cs: `carat`, `cut`, `color`, and `clarity`. It also includes physical measurements such as `depth`, `table`, and dimensions (`x`, `y`, `z`).\n",
    "\n",
    "Additional information is available in the dataset readme.\n",
    "\n",
    "### Caution ðŸ’€ðŸ’€ðŸ’€\n",
    "I'm confident that my analysis is accurate and the model is ready for deployment. However, I had to write the code quickly and some sections might not be up to standard. I apologize for this. Please ensure the codebase is thoroughly refined and optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxXPTfm1-oUN"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzjoKnAj_Qau"
   },
   "source": [
    "## Data Exploration & Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zwl46Igja4HA"
   },
   "source": [
    "### Importing data\n",
    "We base all our analysis on a CSV export of Don Francesco's database. There may be other samples, but that's all we were able to get."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O2fyZ7gY-nR5"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "diamonds = pd.read_csv(\"https://raw.githubusercontent.com/xtreamsrl/xtream-ai-assignment-engineer/main/datasets/diamonds/diamonds.csv\")\n",
    "diamonds.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfItiAo6XqDI"
   },
   "source": [
    "First, let us check if there are really no missing data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J4UFsbtrXpzE"
   },
   "source": [
    "diamonds.isna().sum()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMJ4wZoAX0Ch"
   },
   "source": [
    "Great! No missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us check the summary of the dataset."
   ],
   "metadata": {
    "id": "qafR2df-D_ya"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "diamonds.describe()"
   ],
   "metadata": {
    "id": "x_2_mn7wD-P2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGa0USzzhUuT"
   },
   "source": [
    "There is something wrong. Negative prices and zero-dimensional stones are the result of mistakes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sofiAY9mhcv4"
   },
   "source": [
    "diamonds[diamonds.x * diamonds.y * diamonds.z == 0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "diamonds[diamonds.price <= 0]"
   ],
   "metadata": {
    "id": "QDDB4iL0EbP-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAcjf7gmh3Mg"
   },
   "source": [
    "That's not good. Let us remove those samples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_p3rCZo4iAHH"
   },
   "source": [
    "diamonds = diamonds[(diamonds.x * diamonds.y * diamonds.z != 0) & (diamonds.price > 0)]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvCkpgHwh0EG"
   },
   "source": [
    "Let us check again."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kGyx0cVbBd2u"
   },
   "source": [
    "diamonds.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAsgGwtzBXjL"
   },
   "source": [
    "Good, no more strange values. It looks like the distributions of the numerical variables are quite skewed: there are a few very big values and lots of smaller ones. Let us take a look to the charts.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JQbwLNIT-FP2"
   },
   "source": [
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(diamonds.select_dtypes(include=['number']), figsize=(14, 10));"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjXEjFw4fRra"
   },
   "source": [
    "We see several interesting things:\n",
    "1. There are variables which does not look very correlated with the target (e.g table)\n",
    "2. There are variables which look very correlated with the target, like carat, x, y and z, with non-linear patterns\n",
    "3. There are variables which look correlated with each other (e.g. x, y and z)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThHOOVc3gqQm"
   },
   "source": [
    "Then, let us look into the distribution of single variables. We can use histograms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EwwDEsGDgwF-"
   },
   "source": [
    "diamonds.hist(bins=100, figsize=(14, 10));"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25zL-zXriv37"
   },
   "source": [
    "There are some outliers and it may be a good idea to remove them, but we will not do that at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIVTWb9Ci49u"
   },
   "source": [
    "Let us explore categorical variables: cut, color and clarity.\n",
    "\n",
    "We can use box or violin charts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qy4fXcLVUslw"
   },
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_diamonds_price_by(diamonds_df, cut_column):\n",
    "  return px.violin(diamonds_df, x=cut_column, y='price', color=cut_column, title=f'Price by {cut_column}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cbl_Fm3eWGdn"
   },
   "source": [
    "plot_diamonds_price_by(diamonds, 'cut')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nENHR9Dblfra"
   },
   "source": [
    "plot_diamonds_price_by(diamonds, 'color')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mRmSKoFrlkgb"
   },
   "source": [
    "plot_diamonds_price_by(diamonds, 'clarity')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmLOGd3TmHBk"
   },
   "source": [
    "The distribution of the price differs with the values of each categorical variable. Therefore, it looks like all the variables may add relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVcqNeGjYr8m"
   },
   "source": [
    "To assess relationships between multiple variables, we need to map each one to a different graphical element, or aesthetic.\n",
    "\n",
    "For instance, we can perform a scatter of price vs weight, with the categorical varaibles cut, color and clarity as color."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3NsoaG7TYq1G"
   },
   "source": [
    "def scatter_diamods_by(diamonds_df, cut_column):\n",
    "  return px.scatter(diamonds_df, x='carat', y='price', color=cut_column, title=f'Price vs carat with {cut_column}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AA6jZfKfZyPH"
   },
   "source": [
    "scatter_diamods_by(diamonds, 'cut')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "elmj7YYFZ00e"
   },
   "source": [
    "scatter_diamods_by(diamonds, 'clarity')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qUXNs2wtZ3n9"
   },
   "source": [
    "scatter_diamods_by(diamonds, 'color')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyUvgc1qZ9Ml"
   },
   "source": [
    "The scatter plots confirm that all the categorical variables are relevant because, when we control for the weight of the stone, the categorical variables explain part of the remaining variance in the price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOjHKnw5mUZt"
   },
   "source": [
    "## Linear Model\n",
    "\n",
    "We'll begin with our preferred baseline: a straightforward, fully explainable linear model. However, we need to apply some transformations to the dataset before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcWuxSFMmdcK"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "First, we are going to drop all the irrelevant columns, namely depth and table.\n",
    "\n",
    "Moreover, we also want to drop y and z, as they have high correlation with x."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lSrwFoXomdAP"
   },
   "source": [
    "diamonds_processed = diamonds.drop(columns=['depth', 'table', 'y', 'z'])\n",
    "diamonds_processed.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9yyDREnnAqt"
   },
   "source": [
    "Then, we are going to create dummy variables for cut, color and clarity.\n",
    "\n",
    "Pandas has a very handy function for that."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8ZgRG3gdmZsZ"
   },
   "source": [
    "diamonds_dummy = pd.get_dummies(diamonds_processed, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "diamonds_dummy.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4EcAkXn2Jk"
   },
   "source": [
    "Finally, we split X and Y, train and test.\n",
    "\n",
    "We go for a random 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "18VWN97yfRRt"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = diamonds_dummy.drop(columns='price')\n",
    "y = diamonds_dummy.price\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsgqOgmYM3YC"
   },
   "source": [
    "### Modelling & evaluation\n",
    "\n",
    "We will use a simple linear regression model.\n",
    "\n",
    "We train the model and we evaluate its out-of-sample performances using r squared and Mean Absolute Error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X0uCs0UqorBz"
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "pred = reg.predict(x_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lz9zi76npIAr"
   },
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "print(f'R2 Score: {round(r2_score(y_test, pred), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(y_test, pred), 2)}$')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOmqrRRUp1LT"
   },
   "source": [
    "Let us visualize our results in a goodness of fit plot."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oxrrKgiap5Ym"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gof(y_true: pd.Series, y_pred: pd.Series):\n",
    "  plt.plot(y_true, y_pred, '.')\n",
    "  plt.plot(y_true, y_true, linewidth=3, c='black')\n",
    "  plt.xlabel('Actual')\n",
    "  plt.ylabel('Predicted')\n",
    "  plt.show()\n",
    "\n",
    "plot_gof(y_test, pred)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co3fVHNbrC4S"
   },
   "source": [
    "That's not good at all. We have some negative predicted prices.\n",
    "\n",
    "To avoid this issue, we can perform a log transformation on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eG--6V93rNUT"
   },
   "source": [
    "y_train_log = np.log(y_train)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train_log)\n",
    "pred_log = reg.predict(x_test)\n",
    "pred = np.exp(pred_log)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODfaEhW4rfoP"
   },
   "source": [
    "And we can check the same metrics as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c2sMlXpMrjkA"
   },
   "source": [
    "print(f'R2 Score: {round(r2_score(y_test, pred), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(y_test, pred), 2)}$')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWE6BpkCrouP"
   },
   "source": [
    "Much, much better. Again, we can visually assess the improvement."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TpHxvdPxrnuo"
   },
   "source": [
    "plot_gof(y_test, pred)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient boosting\n",
    "The linear regression is fun and simple, but more advanced models may be needed in order to achieve better performance. Let us try with xgboost."
   ],
   "metadata": {
    "id": "PfKN6zLIGB8X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation\n",
    "We know that tree-based models do not suffer from collinear variables and prefer ordinal variables to categorical ones. Therefore, we need to change the preprocessing as well."
   ],
   "metadata": {
    "id": "UOh2l4I_Q3s6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "diamonds_processed_xgb = diamonds.copy()\n",
    "diamonds_processed_xgb['cut'] = pd.Categorical(diamonds_processed_xgb['cut'], categories=['Fair', 'Good', 'Very Good', 'Ideal', 'Premium'], ordered=True)\n",
    "diamonds_processed_xgb['color'] = pd.Categorical(diamonds_processed_xgb['color'], categories=['D', 'E', 'F', 'G', 'H', 'I', 'J'], ordered=True)\n",
    "diamonds_processed_xgb['clarity'] = pd.Categorical(diamonds_processed_xgb['clarity'], categories=['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'I1'], ordered=True)\n",
    "diamonds_processed_xgb.info()"
   ],
   "metadata": {
    "id": "NfeIwjAqGdkj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "By using the same random seed, we ensure that the same samples end up in the test set, therefore the comparison between models is fair."
   ],
   "metadata": {
    "id": "ZfGtxOo0Q7Tu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_train_xbg, x_test_xbg, y_train_xbg, y_test_xbg = train_test_split(diamonds_processed_xgb.drop(columns='price'), diamonds_processed_xgb['price'], test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "awi8HY5jIqto"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelling and Evaluation\n",
    "As before, we train the model and we evaluate it with the same metrics."
   ],
   "metadata": {
    "id": "Dhngznp7RFNB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xgboost\n",
    "\n",
    "xgb = xgboost.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "xgb.fit(x_train_xbg, y_train_xbg)\n",
    "xgb_pred = xgb.predict(x_test_xbg)"
   ],
   "metadata": {
    "id": "7XOvyULrIZTS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'R2 Score: {round(r2_score(y_test_xbg, xgb_pred), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(y_test_xbg, xgb_pred), 2)}$')"
   ],
   "metadata": {
    "id": "3cdFp9JwJUUX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_gof(y_test_xbg, xgb_pred)"
   ],
   "metadata": {
    "id": "K9GwQwURNq7N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much, much better. But we can do even better. Let's try and use optuna, a Bayesian hyperparameter tuning library."
   ],
   "metadata": {
    "id": "jgEt7v4ORM8T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade optuna"
   ],
   "metadata": {
    "id": "EdyabJf2Lehh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    # Define hyperparameters to tune\n",
    "    param = {\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.7]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'enable_categorical': True\n",
    "    }\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_xbg, y_train_xbg, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model = xgboost.XGBRegressor(**param)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    preds = model.predict(x_val)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "\n",
    "    return mae\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='Diamonds XGBoost')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ],
   "metadata": {
    "id": "LDofqFkiKnoE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now re-train the model with the best set of hyperparameters."
   ],
   "metadata": {
    "id": "i8IE7MiNTC0u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "xgb_opt = xgboost.XGBRegressor(**study.best_params, enable_categorical=True, random_state=42)\n",
    "xgb_opt.fit(x_train_xbg, y_train_xbg)\n",
    "xgb_opt_pred = xgb_opt.predict(x_test_xbg)"
   ],
   "metadata": {
    "id": "TdjJfytfNiDg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'R2 Score: {round(r2_score(y_test_xbg, xgb_opt_pred), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(y_test_xbg, xgb_opt_pred), 2)}$')"
   ],
   "metadata": {
    "id": "xH07w6LeLHwK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_gof(y_test_xbg, xgb_pred)"
   ],
   "metadata": {
    "id": "kGGnw4gYLQRF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A modest improvement. The model performs well, especially for smaller and less expensive gems. However, it shows larger errors with bigger stones, which warrants further investigation. For now, this is acceptable."
   ],
   "metadata": {
    "id": "n5yjJ-5pTIqr"
   }
  }
 ]
}
